{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcYcof0SFvYaXxmkgPeedM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PETEROA/AutoML/blob/main/Basic_Distill.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook 2: Basic Knowledge Distillation\n",
        "\n",
        "This notebook implements and compares different knowledge distillation techniques.\n",
        "- Load teacher and student models\n",
        "- Implement multiple distillation loss functions\n",
        "- Train students with different strategies\n",
        "- Compare: Vanilla training vs. Distillation\n",
        "- Measure accuracy retention and speedup\n",
        "\n",
        "Outputs:\n",
        "- Distilled student models\n",
        "- Comparison metrics\n",
        "- Best distillation strategies for NAS"
      ],
      "metadata": {
        "id": "bD-zXOy50oFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhhF1un45bLc",
        "outputId": "71f78f5d-e44a-4b0c-af04-03b013bd7891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check what's in your Google Drive root\n",
        "print(\"Files in MyDrive:\")\n",
        "print(os.listdir('/content/drive/MyDrive'))\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# Check if automl-distill folder exists\n",
        "if os.path.exists('/content/drive/MyDrive/AutoML'):\n",
        "    print(\"\\n✓ automl-distill folder found!\")\n",
        "    print(\"\\nFiles in automl-distill:\")\n",
        "    print(os.listdir('/content/drive/MyDrive/AutoML'))\n",
        "else:\n",
        "    print(\"\\n✗ automl-distill folder NOT found\")\n",
        "    print(\"You need to create it first\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oYY8LO9n8VGZ",
        "outputId": "c42b8f22-d350-49e3-c5b1-531a7457b5fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in MyDrive:\n",
            "['Colab Notebooks', 'Peter', 'Untitled Diagram.drawio', 'T.pdf', 'INTERNATIONAL PASSPORT.pdf', 'Pricilia_Agida.docx', 'BIS_Coursework 2.docx', 'PETER OWAN AGIDA-converted (1).pdf', 'PETER OWAN AGIDA-converted.pdf', '4070 .gdoc', 'CW 3 G4 REPORT.docx', 'FIN_ SPONSORSHIP_.docx', 'NG_CA_EN.docx', 'Lodger_Agreement (Peter Agida).docx', 'Copy of #csquad budget template.xlsx', 'Coach Ticket EURHM942.pdf', 'RSA slides.pptx', 'pres12345.mp4', 'Diagrammatic problem (1).pptx', 'Diagrammatic problem.pptx', 'Diagrammatic problem.gslides', 'Peter+Agida+-+CV.docx', 'BUILDING A MACHINE LEARNING POWERED APPLICATION.gdoc', 'lab.db', 'ASIA_social sector_AI Saturdays.jpeg', 'TEAM MANDELA : Project Proposal.gdoc', 'Resume_1.pdf', 'Untitled document (12).gdoc', 'ML Engineer (1).pdf', 'ML Engineer.pdf', 'Peter_N_CV.gdoc', 'Untitled document (11).gdoc', 'PAPERS REVIEW.gdoc', 'SAFE RL.gdoc', 'SAFE RL.pdf', 'TOTAL CONCERN ASSET LTD.pdf', 'TOTAL CONCERN ASSET LTD.gdoc', 'Untitled document (10).gdoc', 'Pitch_Deck.gdoc', 'Sim Sec.pptx', 'Sim Sec.gslides', 'ABSTRACT.gdoc', 'Holding Deposit Letter 310aR3.pdf', 'Transcripts.pdf', 'Untitled document (9).gdoc', 'Cyber_1.gdoc', 'Risk Analyst.gdoc', 'AI Cover.gdoc', 'Untitled document (8).gdoc', 'Untitled presentation.gslides', 'Peter Agida - New CV.gslides', 'Peter Agida - New CV- Edited.gslides', 'Peter Agida -  CV.pdf', 'Untitled document (7).gdoc', 'M_Poison.gdoc', 'Untitled document (6).gdoc', 'AWS Certified Solutions Architect Slides v38.pdf', 'Untitled document (5).gdoc', 'Untitled document (4).gdoc', 'Peter Agida -  CV (2).gdoc', 'Peter Agida -  CV (1).gdoc', 'Peter Agida -  CV.gdoc', 'Untitled document (3).gdoc', 'Untitled document (2).gdoc', 'Post Training Quant.gdoc', 'Deep_Main (1).gdoc', 'Deepseek.gdoc', 'remit_py.gdoc', 'Investigative Research.ods', 'Untitled spreadsheet.gsheet', 'WM_Digitize.gdoc', '_OceanofPDF.com_Ben_Hogans_Five_Lessons_-_Ben_Hogan (1).pdf', 'WM_oRI.gdoc', 'ADVERSE_Attacks.gdoc', '_OceanofPDF.com_Ben_Hogans_Five_Lessons_-_Ben_Hogan.pdf', 'Deep_Main.gdoc', 'Untitled document (1).gdoc', 'Proj_Proposal.gdoc', 'Personal Statement (1).gdoc', 'Final_Prop.gdoc', 'Untitled document.gdoc', 'NAS.gdoc', 'RetailMate.gslides', 'NAS+KD.gslides', 'NAS_2.gdoc', 'ATAS_req.gdoc', 't.gdoc', 'Paper_2_cons.gdoc', 'first_paper.gdoc', 'Peter Agida_RCV.gdoc', 'Peter_Agida_CV_3.pdf', 'Personal Statement.gdoc', 'Emails.gdoc', 'ML_Proposal.gdoc', 'Compress_Distil.gdoc', 'AutoDistill.gdoc', 'AutoML']\n",
            "\n",
            "============================================================\n",
            "\n",
            "✓ automl-distill folder found!\n",
            "\n",
            "Files in automl-distill:\n",
            "['Basic_Distill.ipynb', 'Utils.py', 'model_analysis_profilling.ipynb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision transformers -q\n",
        "!pip install matplotlib seaborn pandas numpy tqdm -q"
      ],
      "metadata": {
        "id": "bwydjxw_0qr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import json\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add project path BEFORE importing utils\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/AutoML')  # Adjust to your p\n",
        "\n",
        "# Import utilities (adjust path for Colab if needed)\n",
        "try:\n",
        "    from Utils import *\n",
        "except:\n",
        "    print(\"Note: utils.py not found, defining functions inline\")\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Setup directories\n",
        "# For Colab, use: OUTPUT_DIR = Path('/content/drive/MyDrive/AutoML/outputs')\n",
        "# For local/Claude: OUTPUT_DIR = Path('/mnt/user-data/outputs')\n",
        "OUTPUT_DIR = Path('/content/outputs')  # Change this based on your setup\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "MODELS_DIR = OUTPUT_DIR / 'models'\n",
        "MODELS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "RESULTS_DIR = OUTPUT_DIR / 'results'\n",
        "RESULTS_DIR.mkdir(exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcxVLr2g4owC",
        "outputId": "9b3f3319-ac84-4db4-f8d1-5d90a397e636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model profiles from Notebook 1\n",
        "profile_file = OUTPUT_DIR / 'all_model_profiles.json'\n",
        "\n",
        "if profile_file.exists():\n",
        "    with open(profile_file, 'r') as f:\n",
        "        all_profiles = json.load(f)\n",
        "    print(\"✓ Loaded profiles from Notebook 1\")\n",
        "    print(f\"  Vision models: {list(all_profiles.get('vision_models', {}).keys())}\")\n",
        "    print(f\"  Language models: {list(all_profiles.get('language_models', {}).keys())}\")\n",
        "else:\n",
        "    print(\"⚠ Profile file not found - proceeding without it\")\n",
        "    print(\"  (Profiling data is optional for this notebook)\")\n",
        "    all_profiles = {'vision_models': {}, 'language_models': {}}\n",
        "\n",
        "print(\"\\n✓ Ready to proceed with distillation training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmvTOB6j42CP",
        "outputId": "f345d430-b1a9-4f0a-dee4-79fcf8418b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠ Profile file not found - proceeding without it\n",
            "  (Profiling data is optional for this notebook)\n",
            "\n",
            "✓ Ready to proceed with distillation training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 2. Setup Dataset (CIFAR-10 for quick experiments)\n",
        "def get_cifar10_dataloaders(batch_size=32, num_train_samples=5000, num_val_samples=1000):\n",
        "    \"\"\"\n",
        "    Get CIFAR-10 dataloaders\n",
        "    Using subset for faster experiments\n",
        "    \"\"\"\n",
        "    # Data augmentation for training\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    # Download datasets\n",
        "    trainset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=True, download=True, transform=transform_train\n",
        "    )\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=False, download=True, transform=transform_test\n",
        "    )\n",
        "\n",
        "    # Create subsets for faster training\n",
        "    train_indices = torch.randperm(len(trainset))[:num_train_samples]\n",
        "    val_indices = torch.randperm(len(testset))[:num_val_samples]\n",
        "\n",
        "    train_subset = Subset(trainset, train_indices)\n",
        "    val_subset = Subset(testset, val_indices)\n",
        "\n",
        "    # Create dataloaders\n",
        "    trainloader = DataLoader(\n",
        "        train_subset, batch_size=batch_size, shuffle=True, num_workers=2\n",
        "    )\n",
        "\n",
        "    valloader = DataLoader(\n",
        "        val_subset, batch_size=batch_size, shuffle=False, num_workers=2\n",
        "    )\n",
        "\n",
        "    print(f\"Train samples: {len(train_subset)}, Val samples: {len(val_subset)}\")\n",
        "\n",
        "    return trainloader, valloader\n",
        "\n",
        "# Get dataloaders\n",
        "trainloader, valloader = get_cifar10_dataloaders(\n",
        "    batch_size=64,\n",
        "    num_train_samples=10000,  # Use 10k samples for faster training\n",
        "    num_val_samples=2000\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoupMHCDFD_X",
        "outputId": "ae11d402-51b9-4931-bf1d-2aa6518da141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:10<00:00, 16.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 10000, Val samples: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 3. Load Teacher and Student Models\n",
        "def load_model_for_cifar(model_name, num_classes=10, pretrained=True):\n",
        "    \"\"\"Load and adapt model for CIFAR-10\"\"\"\n",
        "    if model_name == 'resnet18':\n",
        "        model = models.resnet18(pretrained=pretrained)\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    elif model_name == 'resnet50':\n",
        "        model = models.resnet50(pretrained=pretrained)\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    elif model_name == 'mobilenet_v2':\n",
        "        model = models.mobilenet_v2(pretrained=pretrained)\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "    else:\n",
        "        raise ValueError(f\"Model {model_name} not supported\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Load teacher (ResNet-50) and student (ResNet-18)\n",
        "teacher = load_model_for_cifar('resnet50', pretrained=True).to(device)\n",
        "student = load_model_for_cifar('resnet18', pretrained=True).to(device)\n",
        "\n",
        "teacher.eval()\n",
        "\n",
        "# Count parameters\n",
        "teacher_params = sum(p.numel() for p in teacher.parameters())\n",
        "student_params = sum(p.numel() for p in student.parameters())\n",
        "\n",
        "print(f\"\\nTeacher (ResNet-50): {teacher_params:,} parameters\")\n",
        "print(f\"Student (ResNet-18): {student_params:,} parameters\")\n",
        "print(f\"Compression ratio: {teacher_params / student_params:.2f}x\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ8kuw21Fb0u",
        "outputId": "501699b6-4355-49aa-ff98-3519465add35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 77.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 68.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Teacher (ResNet-50): 23,528,522 parameters\n",
            "Student (ResNet-18): 11,181,642 parameters\n",
            "Compression ratio: 2.10x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 4. Distillation Loss Functions\n",
        "class DistillationLoss(nn.Module):\n",
        "    \"\"\"Combined distillation loss\"\"\"\n",
        "    def __init__(self, alpha=0.5, temperature=3.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "        self.ce_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, student_logits, teacher_logits, targets):\n",
        "        # Hard label loss\n",
        "        hard_loss = self.ce_loss(student_logits, targets)\n",
        "\n",
        "        # Soft label loss (KL divergence)\n",
        "        soft_loss = self.kl_divergence_loss(student_logits, teacher_logits)\n",
        "\n",
        "        # Combined loss\n",
        "        total_loss = self.alpha * soft_loss + (1 - self.alpha) * hard_loss\n",
        "\n",
        "        return total_loss, hard_loss, soft_loss\n",
        "\n",
        "    def kl_divergence_loss(self, student_logits, teacher_logits):\n",
        "        \"\"\"KL divergence loss with temperature\"\"\"\n",
        "        student_soft = F.log_softmax(student_logits / self.temperature, dim=1)\n",
        "        teacher_soft = F.softmax(teacher_logits / self.temperature, dim=1)\n",
        "\n",
        "        kl_loss = F.kl_div(\n",
        "            student_soft,\n",
        "            teacher_soft,\n",
        "            reduction='batchmean'\n",
        "        ) * (self.temperature ** 2)\n",
        "\n",
        "        return kl_loss\n",
        "\n",
        "class FeatureMatchingLoss(nn.Module):\n",
        "    \"\"\"Feature matching loss for intermediate layers\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "\n",
        "    def forward(self, student_features, teacher_features):\n",
        "        # Normalize features\n",
        "        student_norm = F.normalize(student_features, p=2, dim=1)\n",
        "        teacher_norm = F.normalize(teacher_features, p=2, dim=1)\n",
        "\n",
        "        return self.mse_loss(student_norm, teacher_norm)"
      ],
      "metadata": {
        "id": "R7hCWQaFFmfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 5. Training Functions\n",
        "def train_with_distillation(\n",
        "    student,\n",
        "    teacher,\n",
        "    trainloader,\n",
        "    valloader,\n",
        "    num_epochs=5,\n",
        "    alpha=0.5,\n",
        "    temperature=3.0,\n",
        "    lr=0.001,\n",
        "    device='cuda'\n",
        "):\n",
        "    \"\"\"\n",
        "    Train student model with knowledge distillation\n",
        "    \"\"\"\n",
        "    student.train()\n",
        "    teacher.eval()\n",
        "\n",
        "    optimizer = torch.optim.Adam(student.parameters(), lr=lr)\n",
        "    criterion = DistillationLoss(alpha=alpha, temperature=temperature)\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_acc': [],\n",
        "        'val_loss': [],\n",
        "        'val_acc': [],\n",
        "        'hard_loss': [],\n",
        "        'soft_loss': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        student.train()\n",
        "        train_loss = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        hard_losses = 0\n",
        "        soft_losses = 0\n",
        "\n",
        "        pbar = tqdm(trainloader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
        "        for images, labels in pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            student_logits = student(images)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                teacher_logits = teacher(images)\n",
        "\n",
        "            # Compute loss\n",
        "            loss, hard_loss, soft_loss = criterion(student_logits, teacher_logits, labels)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            train_loss += loss.item()\n",
        "            hard_losses += hard_loss.item()\n",
        "            soft_losses += soft_loss.item()\n",
        "            _, predicted = student_logits.max(1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            pbar.set_postfix({\n",
        "                'loss': loss.item(),\n",
        "                'acc': 100. * train_correct / train_total\n",
        "            })\n",
        "\n",
        "        train_loss /= len(trainloader)\n",
        "        train_acc = 100. * train_correct / train_total\n",
        "        hard_losses /= len(trainloader)\n",
        "        soft_losses /= len(trainloader)\n",
        "\n",
        "        # Validation\n",
        "        val_loss, val_acc = evaluate_model(student, valloader, device)\n",
        "\n",
        "        # Save history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['hard_loss'].append(hard_losses)\n",
        "        history['soft_loss'].append(soft_losses)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.2f}%, \"\n",
        "              f\"Val Loss={val_loss:.4f}, Val Acc={val_acc:.2f}%\")\n",
        "\n",
        "    return student, history\n",
        "\n",
        "def train_vanilla(\n",
        "    model,\n",
        "    trainloader,\n",
        "    valloader,\n",
        "    num_epochs=5,\n",
        "    lr=0.001,\n",
        "    device='cuda'\n",
        "):\n",
        "    \"\"\"\n",
        "    Train model without distillation (baseline)\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_acc': [],\n",
        "        'val_loss': [],\n",
        "        'val_acc': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        pbar = tqdm(trainloader, desc=f'Epoch {epoch+1}/{num_epochs} (Vanilla)')\n",
        "        for images, labels in pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            pbar.set_postfix({\n",
        "                'loss': loss.item(),\n",
        "                'acc': 100. * train_correct / train_total\n",
        "            })\n",
        "\n",
        "        train_loss /= len(trainloader)\n",
        "        train_acc = 100. * train_correct / train_total\n",
        "\n",
        "        # Validation\n",
        "        val_loss, val_acc = evaluate_model(model, valloader, device)\n",
        "\n",
        "        # Save history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.2f}%, \"\n",
        "              f\"Val Loss={val_loss:.4f}, Val Acc={val_acc:.2f}%\")\n",
        "\n",
        "    return model, history\n",
        "\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    \"\"\"Evaluate model on validation set\"\"\"\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = 100. * correct / total\n",
        "\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "4tx_JA_dFsGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 6. Experiment 1: Vanilla Training (Baseline)\n",
        "print(\"=\"*80)\n",
        "print(\"EXPERIMENT 1: Vanilla Training (Baseline)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create fresh student model\n",
        "student_vanilla = load_model_for_cifar('resnet18', pretrained=True).to(device)\n",
        "\n",
        "# Train\n",
        "student_vanilla, history_vanilla = train_vanilla(\n",
        "    student_vanilla,\n",
        "    trainloader,\n",
        "    valloader,\n",
        "    num_epochs=5,\n",
        "    lr=0.001,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# Save model\n",
        "torch.save(student_vanilla.state_dict(), MODELS_DIR / 'student_vanilla.pth')\n",
        "print(f\"\\n✓ Vanilla student saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4ev8GU4FxmC",
        "outputId": "98cd5708-dcd0-4a67-d124-ef49cee287b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "EXPERIMENT 1: Vanilla Training (Baseline)\n",
            "================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 (Vanilla): 100%|██████████| 157/157 [02:56<00:00,  1.13s/it, loss=1.53, acc=45.7]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss=1.5460, Train Acc=45.70%, Val Loss=2.2260, Val Acc=51.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/5 (Vanilla): 100%|██████████| 157/157 [02:54<00:00,  1.11s/it, loss=1.32, acc=60.6]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: Train Loss=1.1443, Train Acc=60.56%, Val Loss=1.1473, Val Acc=61.15%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/5 (Vanilla): 100%|██████████| 157/157 [02:55<00:00,  1.12s/it, loss=1.02, acc=65.6]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: Train Loss=1.0043, Train Acc=65.57%, Val Loss=0.9849, Val Acc=66.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5 (Vanilla): 100%|██████████| 157/157 [02:59<00:00,  1.14s/it, loss=1.28, acc=68.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss=0.9374, Train Acc=68.38%, Val Loss=0.8555, Val Acc=70.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5 (Vanilla): 100%|██████████| 157/157 [03:01<00:00,  1.15s/it, loss=1.29, acc=71.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss=0.8356, Train Acc=71.73%, Val Loss=0.8039, Val Acc=71.80%\n",
            "\n",
            "✓ Vanilla student saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 7. Experiment 2: Knowledge Distillation with Different Temperatures\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXPERIMENT 2: Knowledge Distillation (Temperature Sweep)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "temperatures = [2.0, 3.0, 5.0]\n",
        "distillation_results = {}\n",
        "\n",
        "for temp in temperatures:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training with Temperature = {temp}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Create fresh student model\n",
        "    student_kd = load_model_for_cifar('resnet18', pretrained=True).to(device)\n",
        "\n",
        "    # Train with distillation\n",
        "    student_kd, history_kd = train_with_distillation(\n",
        "        student_kd,\n",
        "        teacher,\n",
        "        trainloader,\n",
        "        valloader,\n",
        "        num_epochs=5,\n",
        "        alpha=0.5,\n",
        "        temperature=temp,\n",
        "        lr=0.001,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Save model and results\n",
        "    torch.save(student_kd.state_dict(), MODELS_DIR / f'student_kd_temp{temp}.pth')\n",
        "    distillation_results[f'temp_{temp}'] = history_kd\n",
        "\n",
        "    print(f\"\\n✓ Student with T={temp} saved\")\n",
        "\n",
        "    # Clean up\n",
        "    del student_kd\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5DQx51ZuJxI3",
        "outputId": "d9f7489c-8a5b-480c-fde6-785774e60b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "EXPERIMENT 2: Knowledge Distillation (Temperature Sweep)\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "Training with Temperature = 2.0\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 157/157 [04:10<00:00,  1.59s/it, loss=1.07, acc=46.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss=1.0164, Train Acc=46.33%, Val Loss=1.4894, Val Acc=56.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 157/157 [04:20<00:00,  1.66s/it, loss=0.915, acc=58.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss=0.9159, Train Acc=58.49%, Val Loss=1.4537, Val Acc=59.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 157/157 [04:19<00:00,  1.66s/it, loss=1.02, acc=64.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss=0.8565, Train Acc=64.84%, Val Loss=1.2207, Val Acc=67.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 157/157 [04:17<00:00,  1.64s/it, loss=1.02, acc=68.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss=0.8232, Train Acc=68.25%, Val Loss=1.2074, Val Acc=66.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 157/157 [04:16<00:00,  1.63s/it, loss=0.887, acc=69.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss=0.8128, Train Acc=69.48%, Val Loss=1.2670, Val Acc=65.10%\n",
            "\n",
            "✓ Student with T=2.0 saved\n",
            "\n",
            "============================================================\n",
            "Training with Temperature = 3.0\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 157/157 [04:22<00:00,  1.67s/it, loss=0.814, acc=43.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss=1.0308, Train Acc=43.89%, Val Loss=1.5274, Val Acc=54.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 157/157 [04:17<00:00,  1.64s/it, loss=1.05, acc=60.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss=0.8858, Train Acc=60.90%, Val Loss=1.5059, Val Acc=57.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 157/157 [04:19<00:00,  1.65s/it, loss=0.787, acc=63.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss=0.8544, Train Acc=63.89%, Val Loss=1.2628, Val Acc=65.95%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 157/157 [04:22<00:00,  1.67s/it, loss=1.12, acc=68.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss=0.8144, Train Acc=68.45%, Val Loss=1.1803, Val Acc=69.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 157/157 [04:20<00:00,  1.66s/it, loss=0.81, acc=70.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss=0.7951, Train Acc=70.67%, Val Loss=1.1564, Val Acc=72.15%\n",
            "\n",
            "✓ Student with T=3.0 saved\n",
            "\n",
            "============================================================\n",
            "Training with Temperature = 5.0\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 157/157 [04:12<00:00,  1.61s/it, loss=0.997, acc=44]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss=1.0249, Train Acc=44.04%, Val Loss=1.5759, Val Acc=53.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 157/157 [04:11<00:00,  1.60s/it, loss=0.934, acc=60.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss=0.8847, Train Acc=60.45%, Val Loss=1.3386, Val Acc=61.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 157/157 [04:11<00:00,  1.60s/it, loss=0.98, acc=66.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss=0.8272, Train Acc=66.39%, Val Loss=1.2839, Val Acc=64.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 157/157 [04:12<00:00,  1.61s/it, loss=0.922, acc=67.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss=0.8173, Train Acc=67.47%, Val Loss=1.2048, Val Acc=67.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 157/157 [04:13<00:00,  1.61s/it, loss=0.712, acc=70.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss=0.7856, Train Acc=70.07%, Val Loss=1.1238, Val Acc=70.95%\n",
            "\n",
            "✓ Student with T=5.0 saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 7. Experiment 2: Knowledge Distillation with Different Temperatures\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXPERIMENT 2: Knowledge Distillation (Temperature Sweep)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "temperatures = [2.0, 3.0, 5.0]\n",
        "distillation_results = {}\n",
        "\n",
        "for temp in temperatures:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training with Temperature = {temp}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Create fresh student model\n",
        "    student_kd = load_model_for_cifar('resnet18', pretrained=True).to(device)\n",
        "\n",
        "    # Train with distillation\n",
        "    student_kd, history_kd = train_with_distillation(\n",
        "        student_kd,\n",
        "        teacher,\n",
        "        trainloader,\n",
        "        valloader,\n",
        "        num_epochs=5,\n",
        "        alpha=0.5,\n",
        "        temperature=temp,\n",
        "        lr=0.001,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Save model and results\n",
        "    torch.save(student_kd.state_dict(), MODELS_DIR / f'student_kd_temp{temp}.pth')\n",
        "    distillation_results[f'temp_{temp}'] = history_kd\n",
        "\n",
        "    print(f\"\\n✓ Student with T={temp} saved\")\n",
        "\n",
        "    # Clean up\n",
        "    del student_kd\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o88Uqi6NP9Ci",
        "outputId": "a01c8299-542b-4867-cf2b-9428d06411b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "EXPERIMENT 2: Knowledge Distillation (Temperature Sweep)\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "Training with Temperature = 2.0\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 157/157 [04:22<00:00,  1.67s/it, loss=0.884, acc=42.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss=1.0430, Train Acc=42.34%, Val Loss=1.4447, Val Acc=59.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 157/157 [04:22<00:00,  1.67s/it, loss=0.842, acc=59.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss=0.9030, Train Acc=59.64%, Val Loss=1.2735, Val Acc=66.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 157/157 [04:20<00:00,  1.66s/it, loss=0.798, acc=65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss=0.8565, Train Acc=65.05%, Val Loss=1.3287, Val Acc=64.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 157/157 [04:23<00:00,  1.68s/it, loss=0.763, acc=68.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss=0.8210, Train Acc=68.32%, Val Loss=1.2249, Val Acc=66.95%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 157/157 [04:16<00:00,  1.64s/it, loss=0.706, acc=70.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss=0.7951, Train Acc=70.90%, Val Loss=1.1767, Val Acc=69.45%\n",
            "\n",
            "✓ Student with T=2.0 saved\n",
            "\n",
            "============================================================\n",
            "Training with Temperature = 3.0\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 157/157 [04:16<00:00,  1.63s/it, loss=0.811, acc=43.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss=1.0317, Train Acc=43.58%, Val Loss=1.4196, Val Acc=58.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 157/157 [04:14<00:00,  1.62s/it, loss=0.938, acc=58.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss=0.9060, Train Acc=58.83%, Val Loss=1.3301, Val Acc=63.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 157/157 [04:18<00:00,  1.64s/it, loss=0.906, acc=63.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss=0.8625, Train Acc=63.32%, Val Loss=1.3864, Val Acc=61.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 157/157 [04:16<00:00,  1.63s/it, loss=0.622, acc=67.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss=0.8232, Train Acc=67.26%, Val Loss=1.2210, Val Acc=68.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 157/157 [04:20<00:00,  1.66s/it, loss=0.914, acc=68.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss=0.8095, Train Acc=68.72%, Val Loss=1.4277, Val Acc=61.35%\n",
            "\n",
            "✓ Student with T=3.0 saved\n",
            "\n",
            "============================================================\n",
            "Training with Temperature = 5.0\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 157/157 [04:16<00:00,  1.64s/it, loss=1.08, acc=43.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss=1.0360, Train Acc=43.56%, Val Loss=1.4189, Val Acc=58.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 157/157 [04:16<00:00,  1.64s/it, loss=0.991, acc=59.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss=0.8920, Train Acc=59.84%, Val Loss=1.5631, Val Acc=52.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 157/157 [04:20<00:00,  1.66s/it, loss=0.915, acc=62.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss=0.8687, Train Acc=62.44%, Val Loss=1.2384, Val Acc=65.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 157/157 [04:15<00:00,  1.63s/it, loss=0.795, acc=65.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss=0.8332, Train Acc=65.32%, Val Loss=1.1911, Val Acc=68.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 157/157 [04:21<00:00,  1.66s/it, loss=0.98, acc=69.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss=0.7973, Train Acc=69.56%, Val Loss=1.3171, Val Acc=62.45%\n",
            "\n",
            "✓ Student with T=5.0 saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8 . Experiment 3: Different Alpha Values\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXPERIMENT 3: Knowledge Distillation (Alpha Sweep)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "alphas = [0.3, 0.5, 0.7]\n",
        "alpha_results = {}\n",
        "\n",
        "for alpha in alphas:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training with Alpha = {alpha}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Create fresh student model\n",
        "    student_kd = load_model_for_cifar('resnet18', pretrained=True).to(device)\n",
        "\n",
        "    # Train with distillation\n",
        "    student_kd, history_kd = train_with_distillation(\n",
        "        student_kd,\n",
        "        teacher,\n",
        "        trainloader,\n",
        "        valloader,\n",
        "        num_epochs=5,\n",
        "        alpha=alpha,\n",
        "        temperature=3.0,\n",
        "        lr=0.001,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Save model and results\n",
        "    torch.save(student_kd.state_dict(), MODELS_DIR / f'student_kd_alpha{alpha}.pth')\n",
        "    alpha_results[f'alpha_{alpha}'] = history_kd\n",
        "\n",
        "    print(f\"\\n✓ Student with alpha={alpha} saved\")\n",
        "\n",
        "    # Clean up\n",
        "    del student_kd\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None"
      ],
      "metadata": {
        "id": "e9t-lk1gqQqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 9. Comparison & Visualization\n",
        "# Compile all results\n",
        "all_results = {\n",
        "    'vanilla': history_vanilla,\n",
        "    **distillation_results,\n",
        "    **alpha_results\n",
        "}\n",
        "\n",
        "# Create comparison DataFrame\n",
        "comparison_data = []\n",
        "for name, history in all_results.items():\n",
        "    comparison_data.append({\n",
        "        'Method': name,\n",
        "        'Final Train Acc': history['train_acc'][-1],\n",
        "        'Final Val Acc': history['val_acc'][-1],\n",
        "        'Best Val Acc': max(history['val_acc']),\n",
        "        'Final Train Loss': history['train_loss'][-1],\n",
        "        'Final Val Loss': history['val_loss'][-1]\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "comparison_df = comparison_df.sort_values('Best Val Acc', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DISTILLATION RESULTS COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Save comparison\n",
        "comparison_df.to_csv(RESULTS_DIR / 'distillation_comparison.csv', index=False)"
      ],
      "metadata": {
        "id": "vtNbX_8TLH8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization 1: Validation Accuracy Comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Plot 1: Val Accuracy over epochs\n",
        "for name, history in all_results.items():\n",
        "    axes[0].plot(history['val_acc'], marker='o', label=name)\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Validation Accuracy (%)')\n",
        "axes[0].set_title('Validation Accuracy Comparison')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True)\n",
        "\n",
        "# Plot 2: Final accuracy comparison\n",
        "methods = comparison_df['Method'].tolist()\n",
        "accuracies = comparison_df['Best Val Acc'].tolist()\n",
        "colors = ['red' if 'vanilla' in m else 'green' for m in methods]\n",
        "\n",
        "axes[1].barh(methods, accuracies, color=colors, alpha=0.7)\n",
        "axes[1].set_xlabel('Best Validation Accuracy (%)')\n",
        "axes[1].set_title('Final Accuracy Comparison')\n",
        "axes[1].grid(True, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / 'distillation_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✓ Visualization saved to:\", OUTPUT_DIR / 'distillation_comparison.png')"
      ],
      "metadata": {
        "id": "CShOBTXtLP9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization 2: Loss Components (for distillation methods)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "for name, history in distillation_results.items():\n",
        "    if 'hard_loss' in history:\n",
        "        axes[0].plot(history['hard_loss'], marker='o', label=name)\n",
        "        axes[1].plot(history['soft_loss'], marker='s', label=name)\n",
        "\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Hard Loss (Cross-Entropy)')\n",
        "axes[0].set_title('Hard Label Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True)\n",
        "\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Soft Loss (KL Divergence)')\n",
        "axes[1].set_title('Knowledge Distillation Loss')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / 'loss_components.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Loss components visualization saved\")"
      ],
      "metadata": {
        "id": "SbV2pPtJLUkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 10. Key Findings & Recommendations for NAS\n",
        "# Find best configuration\n",
        "best_method = comparison_df.iloc[0]\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"KEY FINDINGS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\n✓ Best Method: {best_method['Method']}\")\n",
        "print(f\"  - Validation Accuracy: {best_method['Best Val Acc']:.2f}%\")\n",
        "print(f\"  - Improvement over vanilla: {best_method['Best Val Acc'] - comparison_df[comparison_df['Method']=='vanilla']['Best Val Acc'].values[0]:.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RECOMMENDATIONS FOR NAS (NOTEBOOK 3)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Temperature recommendations\n",
        "temp_results = {k: v['val_acc'][-1] for k, v in distillation_results.items()}\n",
        "best_temp = max(temp_results, key=temp_results.get)\n",
        "print(f\"\\n1. Temperature Range:\")\n",
        "print(f\"   - Best: {best_temp}\")\n",
        "print(f\"   - Recommended search space: [2.0, 3.0, 4.0, 5.0]\")\n",
        "\n",
        "# Alpha recommendations\n",
        "alpha_vals = {k: v['val_acc'][-1] for k, v in alpha_results.items()}\n",
        "best_alpha = max(alpha_vals, key=alpha_vals.get)\n",
        "print(f\"\\n2. Alpha (Distillation Weight):\")\n",
        "print(f\"   - Best: {best_alpha}\")\n",
        "print(f\"   - Recommended search space: [0.3, 0.5, 0.7, 0.9]\")\n",
        "\n",
        "print(f\"\\n3. Distillation is effective:\")\n",
        "vanilla_acc = comparison_df[comparison_df['Method']=='vanilla']['Best Val Acc'].values[0]\n",
        "best_distill_acc = comparison_df[comparison_df['Method']!='vanilla']['Best Val Acc'].max()\n",
        "improvement = best_distill_acc - vanilla_acc\n",
        "print(f\"   - Average improvement: {improvement:.2f}% over vanilla training\")\n",
        "print(f\"   - Distillation SHOULD be included in NAS search space\")\n",
        "\n",
        "# Save recommendations\n",
        "recommendations = {\n",
        "    'best_method': best_method['Method'],\n",
        "    'best_accuracy': float(best_method['Best Val Acc']),\n",
        "    'improvement_over_vanilla': float(improvement),\n",
        "    'recommended_temperature_range': [2.0, 3.0, 4.0, 5.0],\n",
        "    'recommended_alpha_range': [0.3, 0.5, 0.7, 0.9],\n",
        "    'best_temperature': best_temp,\n",
        "    'best_alpha': best_alpha\n",
        "}\n",
        "\n",
        "with open(RESULTS_DIR / 'distillation_recommendations.json', 'w') as f:\n",
        "    json.dump(recommendations, f, indent=2)\n",
        "\n",
        "print(f\"\\n✓ Recommendations saved to: {RESULTS_DIR / 'distillation_recommendations.json'}\")"
      ],
      "metadata": {
        "id": "8oB73aGBLZuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 11. Save All Results\n",
        "# Save all training histories\n",
        "with open(RESULTS_DIR / 'all_training_histories.json', 'w') as f:\n",
        "    json.dump(all_results, f, indent=2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"OUTPUTS CREATED\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\n1. Models saved in: {MODELS_DIR}\")\n",
        "print(f\"   - student_vanilla.pth\")\n",
        "print(f\"   - student_kd_temp*.pth (multiple temperatures)\")\n",
        "print(f\"   - student_kd_alpha*.pth (multiple alphas)\")\n",
        "\n",
        "print(f\"\\n2. Results saved in: {RESULTS_DIR}\")\n",
        "print(f\"   - distillation_comparison.csv\")\n",
        "print(f\"   - distillation_recommendations.json\")\n",
        "print(f\"   - all_training_histories.json\")\n",
        "\n",
        "print(f\"\\n3. Visualizations saved in: {OUTPUT_DIR}\")\n",
        "print(f\"   - distillation_comparison.png\")\n",
        "print(f\"   - loss_components.png\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"NEXT STEPS\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nNotebook 3 will use these results to:\")\n",
        "print(\"  1. Design the NAS search space using recommended ranges\")\n",
        "print(\"  2. Include distillation strategies in architecture search\")\n",
        "print(\"  3. Optimize for accuracy + latency + model size\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "TWx6QZGRLg4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What I accomplished:\n",
        "- Implemented knowledge distillation from ResNet-50 (teacher) to ResNet-18 (student)\n",
        "- Compared vanilla training vs. distillation\n",
        "- Experimented with different temperatures and alpha values\n",
        "- Found optimal distillation hyperparameters\n",
        "\n",
        "Key insights:\n",
        "- Distillation improves student accuracy by ~X% over vanilla training\n",
        "- Temperature and alpha significantly impact performance\n",
        "- Best configuration will be used in NAS search space\n",
        "\n",
        "Files created for next notebooks:\n",
        "- Distilled model checkpoints\n",
        "- Training histories\n",
        "- Hyperparameter recommendations\n",
        "- Comparison metrics"
      ],
      "metadata": {
        "id": "GprOe8CBLsWD"
      }
    }
  ]
}